<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>mgosselin | projects</title>
    <link rel="stylesheet" href="css/foundation.css" />
    <script src="js/vendor/modernizr.js"></script>
  </head>
  <body>
      <!-- Nav Bar -->
 
  <div class="row">
    <div class="large-12 columns">
      <div class="nav-bar right">
       <ul class="button-group">
         <li><a href="https://docs.google.com/file/d/0B_ULpmIPYJmhTHZWVzNLc2pUamc/edit?pli=1" class="button">Resumé</a></li>
         <li><a href="#2" class="button">Link 2</a></li>
        </ul>
      </div>
      <h1>Michael Gosselin <small> ...page in progress</small></h1>
      <hr />
    </div>
  </div>
 
  <!-- End Nav -->
 
  <!-- Main Page Content and Sidebar -->
 
  <div class="row">
 
    <!-- Main Blog Content -->
    <div class="large-9 columns" role="content">

      <!-- Computer Vision -->

      <article>
        <a id="computer_vision"></a>
        <h3><a href="#computer_vision">Automatic Image Stitching</a></h3>
        <h6>December 2013 - With Noam Eisen</h6>
 
        <p>In Computational Photography (CIS 581) at the University of Pennsylvania, I wrote some code for fully-automatic image stitching.  The objective was to take in several images and 'stitch' them together, creating a result which appears natural to the eye.  At the core was the implementation of methods of automatic feature detection and automatic feature matching.  I implemented some of the methods presented in this <a href="http://research.microsoft.com/pubs/70120/tr-2004-133.pdf">article</a> by Brown, Szeliski and Winder.</p>
        
        <div class="row">
          <div class="large-4 columns">
            <img src="img/computer_vision/quad08.jpg"/>
          </div>
          <div class="large-4 columns">
            <img src="img/computer_vision/quad09.jpg"/>
          </div>
          <div class="large-4 columns">
            <img src="img/computer_vision/quad10.jpg"/>
          </div>
        </div>
        
        <br>
        <p>Shown above are three sample images which were taken with overlapping features.  </p>

        <div class="row">
          <div class="large-12 columns">
            <img src="img/computer_vision/stitch_0.jpg"/>
          </div>
        </div>  
        <br>

        <p>After using the matched pairs of features in the images, affine transformations were used to convert the center and right images into the frame of the left image.  Once transformed and overlayed, the edge regions become nearly unnoticeable, so further steps such as edge-smoothing were not necessary.</p>
        <p> </p>
        <p>MATLAB was used throughout.   The project <a href="https://github.com/mgosselin/CIS581">files</a> can be found on GitHub.</p>

      </article>

      <hr />     

      <!-- Train Project -->

      <article>
        <a id="train"></a>
        <h3><a href="#train">PID Control of Lego Trains</a></h3>
        <h6>March 2013 - With <a href="http://www.linkedin.com/pub/chao-qu/22/aab/4ab">Chao Qu</a>.</h6>
 
        <p>The objective of this project was to design a classical controller to maintain a fixed following distance between two miniature lego trains.  However, the controller was required to also handle a 0.1 second time-delay imposed on the system output of the following train.  The lead train simply circled the track with fixed motor output, while the following train carried an ultrasonic distance sensor and an Arduino to measure distance and implement a control routine.</p>

        <p>Initially, we setup a simple proportional derivative controller to observe the system.  Without any modelling, or design effort it behaved like this: </p>
        
        <div class="flex-video">
        <iframe width="420" height="315" src="//www.youtube.com/embed/3vBbpaUcssU" frameborder="0" allowfullscreen></iframe>
        </div>
        <p> </p>

        <p>We sought a controller with good tracking performance and good disturbance rejection, over a broad range of lead train speeds. This posed a particular challenge because running the lead train at different speeds strongly affects the type of disturbance that is ‘seen’ by the following train. The friction change when transitioning from the straight track to the curved track is the source of this disturbance. At high speeds, the lead train’s forward motion is high, and the step-change in track friction at this transition has little effect on it’s velocity. Therefore, the following train ‘sees’ little or no velocity disturbance. </p>

        <p>However at low lead-train speeds, the friction at the transition to the corner has a prominent effect, and creates a step-like decrease in speed (and conversely, a step increase, as the lead train exits the corner shortly after). The magnitude of the step disturbance varies with the lead train speed. For the purposes of this report, we considered two cases although our controller can handle all the in-between operating conditions as well: We wanted to make a controller that could handle two extreme cases, plus all in-between cases.</p>

        <p>CASE 1: fast lead train speed; insignificant velocity-step-disturbances at corner transitions.</p>
        <p>CASE 2: slow lead train speed; significant velocity-step-disturbances at corner transitions.</p>

        <img src="img/train/simulink_model.png"/>

        <p>The system was modelled in MATLAB Simulink, as shown in the diagram above.  The following train transfer function was determined experimentally.  The PID part of the controller was determined using the Zeigler-Nichols method.  The feed-forward term for friction compensation was determined by trial and error.  

        <p>The final controller is shown in use in the video below.  Some integrator windup can still be observed, although it was limited.  Disturbance rejection is greatly improved.  Also, the steady state distance error amplitude is minimized, and oscillation amplitude is low.  

        <div class="flex-video">
        <iframe width="560" height="315" src="//www.youtube.com/embed/1MTd_ycdrv0" frameborder="0" allowfullscreen></iframe>
        </div>

        <p>The <a href="https://github.com/mgosselin/MEAM513">code</a> can be found on GitHub.</p>
      
      </article>

      <hr />

      <!-- PCB Prototyping -->

      <article>
        <a id="pcb_making"></a>
        <h3><a href="#pcb_making">Rapid PCB Prototyping</a></h3>
        <h6>February 2013 - June 2013 - With <a href="http://www.linkedin.com/pub/ryan-wilson/1b/19b/451">Ryan Wilson</a></h6>
 
        <p>As an aside to some of my past electronic hardware projects, I have workied with other mechatronics students to develop increasingly fast and practical PCB prototyping methods.  Fast PCB prototyping is valuable because it permits many design iterations over a short period, sometimes several in one day.  Here is a link to a <a href="https://alliance.seas.upenn.edu/~medesign/wiki/index.php/Guides/S62">wiki article</a> that I co-authored, as a reference and as an instructional resource for other mechatronics students.</p>
        
        <div class="flex-video">
        <iframe width="420" height="315" src="//www.youtube.com/embed/BnK9QVlT-gk" frameborder="0" allowfullscreen></iframe>
        </div>
        <p> </p>

        <div class="row">
          <div class="large-6 columns">
            <p>The method shown involves micro-milling of copper-clad boards using an LPKF S62.  This permitted milling traces and drilling, but no solder mask placement.  In addition, through-hole plating was acheived separately, using solder paste, a mask, and an oven.  Our system permitted traces as small as 8 mil.  Although two-sided boards with through hole plating could be made, even faster prototyping was possible with single-sided designs, using only surface mount components.  This approach permitted very short milling times (as little as 1 hour) and forgoes the through-hole plating steps. </p>
          </div>
          <div class="large-6 columns">
            <img src="img/pcb_making/s62_0.jpg"/>
          </div>
        </div>
      
      </article>

      <hr />

      <!-- mstereo project -->

      <article>
        <a id="mstereo"></a>
        <h3><a href="#mstereo">mStereo</a></h3>
        <h6>January 2013 - ongoing.</h6>

        <p>mStereo is a two-channel digital-to-analog (DAC) converter for audio.  Is is a small part of an eventual comprehensive hardware solution for playback of digital audio files stored on computers, and mobile devices.</p>

        <p>At present, the scope of the hardware has been limited to I2S-to-analog converter.  <a href="https://sparkfun.com/datasheets/BreakoutBoards/I2SBUS.pdf">I2S</a>, introduced Philips, is a standard bus for inter-IC audio communication, with many practical benefits for hardware implementation, and ultimately, for user experience.</p>

        <p>Since computer-based audio has become by far the most flexible and powerful way to store and play audio files, the task remains to develop hardware to accompany computers and provide the best possible user experience. Since I am so passionate about high-fidelity reproduction of audio recordings, developing my own high-performing hardware is rewarding on many fronts.</p>
 
        <p>Practically, this means seeking the best possible hardware components (DAC ICs, oscillators, power supplies, etc.), integrating them, and ensuring their implementation permits their maximum specifications to be realized.</p>
 
        <div class="row">
          <div class="large-4 columns">
            <img src="img/mstereo/board1.jpg"/>
          </div>
          <div class="large-4 columns">
            <img src="img/mstereo/board2.jpg"/>
          </div>
          <div class="large-4 columns">
            <img src="img/mstereo/board3.jpg"/>
          </div>
        </div>

        <br>

        <div class="row">
          <div class="large-6 columns">
            <p>The hardware has gone through 3 iterations.  Each was fabricated and tested using the <a href="#pcb_making">rapid pcb prototyping</a> methods outlined above.  Parts were populated by hand, using solder paste, tweezers, and an oven.  The fourth iteration will be fabricated and tested, and if satisfactory it will be sent out to a professional fab for production with silkscreen and solder mask.  </p>
          </div>
          <div class="large-6 columns">
            <img src="img/mstereo/pop1.jpg"/>
          </div>
        </div>

        <br>

        <!-- <p>Since computer-based audio has become by far the most flexible and powerful way to store and play audio files, the task remains to develop hardware to accompany computers and provide the best possible user experience. Since I am so passionate about high-fidelity reproduction of audio recordings, developing my own high-performing hardware is rewarding on many fronts.</p> -->
 
        <div class="row">
          <div class="large-6 columns">
            <p>At present, mStereo connects to two other peices of hardware.  At the output, there is a high-speed, low-distortion, broadband stereo preamplifier (right).  This is suitable for headphones or connecting to a larger stereo power amplifier for use with loudpeakers.  </p>

            <p>At the input there is a <a href="http://www.amb.org/audio/gamma1/">γ1</a>, which uses a <a href="http://www.ti.com/lit/ds/sles081f/sles081f.pdf">Burr-Brown PCM2707</a> to convert from a computer's USB output (PCM audio) to I2S, wich is passed to mStereo's input.</p>
          </div>
          <div class="large-6 columns">
            <img src="img/mstereo/power_amp.jpg"/>
          </div>
        </div>

        <p>The next addition to mStereo will be the addition of an interface for converting PCM audio to I2S, so that mStereo will no longer rely on the γ1 to perform this conversion. This will support one of two common consumer hardware connections: either USB of S/PDIF.  </p>
 
      </article>

      <hr />

      <!-- Hackathon -->

      <article>
        <a id="hackathon"></a>
        <h3><a href="#hackathon">Hackathon Project: Skynet Command</a></h3>
        <h6>January 2013 - With <a href="http://www.linkedin.com/in/mikelautman">Mike Lautman, </a> <a href="http://www.linkedin.com/pub/steven-xing/43/438/723">Steven Xing</a> and <a href="http://www.linkedin.com/pub/yunkai-cui/63/a05/411">Yunkai (Edward) Cui</a>.</h6>
 
        <p><p>Our hackathon project from the PennApps Spring 2013 Hackathon.  Our project featured two remote controlled mobile robots that battle each other by shooting foam darts.  Both are controlled over the web, and carry a mobile phone (running Android 4.3) on top, permitting the users to stream video wirelessly and visualize their robot's persepective using the tokbok <a href="http://tokbox.com/opentok">OpenTok API</a>.  The <a href="https://github.com/sxing/Skynet">code</a> we put together during the hackathon can be found on GitHub.</p></p>
        
        <div class="flex-video">
        <iframe width="560" height="315" src="//www.youtube.com/embed/QroL27ZyM_Y" frameborder="0" allowfullscreen></iframe>
        </div>
        <p> </p>
      
      </article>

      <hr />

      <!-- Robockey Project -->

      <article>
        <a id="robockey"></a>
        <h3><a href="#robockey">Autonomous Hockey</a></h3>
        <h6>December 2012 - With <a href="http://www.linkedin.com/pub/jialue-huang/62/a7a/965">Jialue Huang, </a> <a href="http://www.linkedin.com/pub/jing-tang/62/850/3bb">Jing Tang</a> and <a href="http://www.linkedin.com/pub/cherng-ru-chuang/63/662/a50">Cherng-Ru (Dennis) Chuang</a></a>.</h6>
 
        <p>In the final project of Mechatronic System Design (MEAM 510) groups of students built teams of three autonomous mobile robots to play hockey against one-another. </p>

        <div class="flex-video">
          <iframe width="420" height="315" src="//www.youtube.com/embed/inIawVVcCBk" frameborder="0" allowfullscreen></iframe>
        </div>
        <p> </p>
        
        <div class="row">
          <div class="large-6 columns">
            <p>Our robots were conceptualized, mechanisms were prototyped, and the final hardware was assembled in a mere 4 weeks.  In addition, code for autonomous gameplay was written from the ground-up, tested, and improved in parallel with the hardware development. Microcontrollers were used onboard each robot for receiving multiple sensor inputs and executing different plays according to a case structure.</P>
            <p> </P>
            <p>Each robot was equipped with a small camera, harvested from inside a Nintendo Wii remote controller, and repurposed for localization.  The camera was oriented toward the ceiling above the playing surface, where there was a cluster of LEDs in a fixed pattern.  As the robots moved they used the detected change in position and orientation of the pattern on the ceiling to determine their own respective changes in position and orientation within the playing space.  Team mate Jing is in the video above, testing the robot's ability to localize and go to a specific position.</p>
            <p> </P>
            <p>Searching for the puck was accomplished by measuring light intensity values from a pair of phototransistors.  Since the puck was constantly emitting infrared light, it's relative position could be approximated by measuring the phototransistors' voltages.  The phototransistors' continuous voltage values were discretized by analog-to-digital converters, onboard the robot's microcontroller.  The discretized quantities were compared in order to determine the robot's target orientation in the playing space.  </P>
            <p> </P>
            <p>The electronic hardware was standardized across the robots, with every component pin-compatible and swappable.  This permitted very fast resolution of broken electronic hardware.  The mechanical hardware, however was unique across each of the three robots.  In addition, unique case-structures were used in each robot's programming, so that each robot could play a different 'role' in the miniature hockey tournament, in order to gain a strategic advantage over the competition.</P>
          </div>

          <div class="large-6 columns">
            <img src="img/robockey/robockey0.JPG" />
          </div>
          <p> </p>
          <div class="large-6 columns">
            <img src="img/robockey/robockey1.JPG" />
          </div>
          <p> </p>
          <div class="large-6 columns">
            <img src="img/robockey/robockey2.jpg" />
          </div>
          <p> </p>
          <div class="large-6 columns">
            <img src="img/robockey/robockey3.JPG" />
          </div>
          <p> </p>
          <div class="large-6 columns">
            <img src="img/robockey/robockey4.JPG" />
          </div>
        </div>
        <br>  
        <div class="row">
          <div class="large-12 columns">
            <img src="img/robockey/robockey5.JPG" />
          </div>
        </div>  
 
      </article>

      <hr />

      <!-- Acrobat Project -->

      <article>
        <a id="acrobat"></a>
        <h3><a href="#acrobat">Balancing Robot</a></h3>
        <h6>October 2012 - With <a href="http://www.linkedin.com/in/mikelautman">Mike Lautman, </a> <a href="http://www.linkedin.com/pub/elizabeth-beattie/88/885/a16">Elizabeth Beattie</a> and <a href="http://www.linkedin.com/pub/yunkai-cui/63/a05/411">Yunkai (Edward) Cui</a>.</h6>
 
        <p>In the fourth project of Mechatronic System Design (MEAM 510) our group built a two-wheeled balancing robot. The robot was designed to be battery powered, and able to hold both it's position and orientation (vertical) on both horizontal and inclined surfaces. </p>

        <div class="flex-video">
        <iframe width="560" height="315" src="//www.youtube.com/embed/g9hoRHFsPFs" frameborder="0" allowfullscreen></iframe>
        </div>
        <p> </p>
        
        <div class="row">
          <div class="large-6 columns">
            <p>The robot used a MEMS accelerometer to measure it's angle of tile with respect to gravity.  The accelerometer module passed it's output to an Atemel Atmega 32u4 microcontroller serially, using I2C.  Using a feedback control routine on the microcontroller, and passing the output to two DC brushed motors, balancing was acheived.  Oscillation was minimized, and in the video above it is nearly unnoticeable because of the carpet beneath the wheels.</p>
          </div>
          <div class="large-6 columns">
            <img src="img/acrobat/acrobat0.jpg" />
          </div>
        </div>

        <div class="flex-video">
        <iframe width="560" height="315" src="//www.youtube.com/embed/Tbr6DUvmqTA" frameborder="0" allowfullscreen></iframe>
        </div>
        <p> </p>

        <p>In addition, we built our own optical quadrature encoders using IR LEDs and phototransistors.  It's output gave a pair of square waves, out of phase by 1/3 period.  The green and blue LEDs in the video above allowed us to visualize the encoder output.  The encoders allowed us to determine both the rotation speed and direction of the wheels on the balancing robot, so that our feedback control loop could bring the robot to a stationary state.</p>
 
      </article>
 
      <hr />

      <!-- Light Painting -->

      <article>
        <a id="light_painting"></a>
        <h3><a href="#light_painting">Light Painting with an RRR Industrial Serial Manipulator.</a></h3>
        <h6>November 2012 - With <a href="http://www.linkedin.com/pub/chao-qu/22/aab/4ab">Chao Qu</a> and <a href="http://www.linkedin.com/pub/yunkai-cui/63/a05/411">Yunkai (Edward) Cui</a>.</h6>

        <div class="row">
          <div class="large-6 columns">
            <p>Implemented both forward and inverse kinematic solutions control an industrial manipulator, using MATLAB.  The code is on this GitHub <a href="https://github.com/mgosselin/MEAM520">repository</a>.  The end effector was removed and instead equipped with an RGB LED.  The LED's intensity and color were varied as the end effector moved through a 2D plane in it's configuration space.  The objective was to resolve some familiar image.  The result is shown to the right.  </p>  
          </div>
          <div class="large-6 columns">
            <img src="img/light_painting/puma0.jpg"/>
          </div>
        </div>
        <br>
        <div class="row">
          <div class="large-6 columns">
            <p>Implemented both forward and inverse kinematic solutions control an industrial manipulator, using MATLAB.  The code is on this GitHub <a href="https://github.com/mgosselin/MEAM520">repository</a>.  The end effector was removed and instead equipped with an RGB LED.  The LED's intensity and color were varied as the end effector moved through a 2D plane in it's configuration space.  The objective was to resolve some familiar image.  The result is shown to the right.  </p>
          </div>
          <div class="large-6 columns">
            <img src="img/light_painting/puma1.JPG"/>
          </div>
        </div>
      
      </article>

      <hr />

      <!-- Power Amplification -->

      <article>
        <a id="amp"></a>
        <h3><a href="#amp">Power Amplification</a></h3>
        <h6>January 2012 - ongoing.</h6>
 
        <p>Power amplifier project.  My implementation of an <a href="http://www.amb.org/audio/mmm/">M3</a>, an high performance open-source stereo power amplifier for audio.</p>
        
<!--         <div class="flex-video">
        <iframe width="560" height="315" src="//www.youtube.com/embed/QroL27ZyM_Y" frameborder="0" allowfullscreen></iframe>
        </div>
        <p> </p> -->

        <div class="row">
          <div class="large-6 columns">
            <p>The M3 is accompanied by a linear regulated power supply. In addition, a DAC and accompanying power supply are housed in the same enclosure.  This minimizes the path from the DAC's analog output to the high-impedance input of the power amplifier.  In addition, rigorous sheilding is used to bring induced voltage noise to a minimum.</p>
          </div>
          <div class="large-6 columns">
            <img src="img/amp/amp0.jpg"/>
          </div>
        </div>
      
      </article>

      
 
    </div>
 
    <!-- End Main Content -->
 
    <!-- Begin Sidebar -->
 
    <aside class="large-3 columns">
 
      <h5>Projects</h5>
      <ul class="side-nav">
        <li><a href="#acrobat">Balancing Robot</a></li>
        <li><a href="#mstereo">mStereo</a></li>
        <li><a href="#robockey">Autonomous Hockey</a></li>
        <li><a href="#pcb_making">Rapid PCB Prototyping</a></li>
        <li><a href="#computer_vision">Image Stitching</a></li>
        <li><a href="#hackathon">Hackathon: mobile robots</a></li>
        <li><a href="#light_painting">Light Painting</a></li>
        <li><a href="#amp">Power Amplification</a></li>
        <li><a href="#train">Classical control</a></li>
      </ul>
 
      <div class="panel">
        <h5>Contact</h5>
        <a href="http://www.linkedin.com/pub/michael-gosselin/2a/78a/431" style="text-decoration:none;"><span style="font: 80% Arial,sans-serif; color:#0783B6;"><img src="http://s.c.lnkd.licdn.com/scds/common/u/img/webpromo/btn_in_20x15.png" width="20" height="15" alt="View Michael Gosselin's LinkedIn profile" style="vertical-align:middle" border="0">LinkedIn</span></a></li>
        <br>
        <br>
        <a href="https://angel.co/michael-gosselin" style="text-decoration:none;"><span style="font: 80% Arial,sans-serif; color:#0783B6;"><img src="http://jamsidedown.com/files/2012/04/angellist-e1335816439171.png" width="17" height="17" alt="View Michael Gosselin's Angel List profile" style="vertical-align:middle" border="0"> Angel List</span></a></li>
        <br>
        <br>
        <a href="https://github.com/mgosselin" style="text-decoration:none;"><span style="font: 80% Arial,sans-serif; color:#0783B6;"><img src="http://spreecommerce.com/images/github-mark.png" width="15" height="15" alt="View Michael Gosselin's Angel List profile" style="vertical-align:middle" border="0"> GitHub</span></a></li>

      </div>
 
    </aside>
 
    <!-- End Sidebar -->

  </div>
 
  <!-- End Main Content and Sidebar -->
 
  <!-- Footer -->
 
  <footer class="row">
    <div class="large-12 columns">
      <hr />
      <div class="row">
        <div class="large-6 columns">
          <p>© 2013 Michael Gosselin</p>
        </div>
        <div class="large-6 columns">
          <ul class="inline-list right">
            <li><a href="#1">Link 1</a></li>
            <li><a href="#2">Link 2</a></li>
            <li><a href="#3">Link 3</a></li>
            <li><a href="#4">Link 4</a></li>
          </ul>
        </div>
      </div>
    </div>
  </footer>
    
  </body>
</html>
